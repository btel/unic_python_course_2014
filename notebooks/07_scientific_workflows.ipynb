{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scientific workflows\n",
    "\n",
    "The examples for the tutorial are in `materials/07_scientific_workflows` directory.\n",
    "\n",
    "To run the examples change to this directory and run either `doit` (you will need to install the [doit](http:/doit.readthedocs.org) library) or `sh run_pipeline.sh`\n",
    "\n",
    "## Example:\n",
    "\n",
    "â€¢ distribution of pairwise correlations\n",
    "\n",
    "## Outline\n",
    "\n",
    "* what is a scientific workflow\n",
    "* points to remember:\n",
    "   - programming in general is an iterative process\n",
    "   - keep it simple stupid\n",
    "   - repetition is the root of all evil\n",
    "   - program to interfaces\n",
    "* three components of scientific workflow:\n",
    "   - data generation (simulation, pre-processing)\n",
    "   - statistics\n",
    "   - plots\n",
    "* two stages of data analysis:\n",
    "   - exploratory on a single (or a few) datasets\n",
    "   - batch analysis\n",
    "* writing simple command line tools\n",
    "   - argparse\n",
    "   - avoid changes in API\n",
    "* saving data to files:\n",
    "   - csv\n",
    "   - compare pickle and npz\n",
    "* writing meta-scripts in bash/python\n",
    "* running batch analyses\n",
    "* using automatic builders (doit)\n",
    "\n",
    "# Plan:\n",
    "\n",
    "1) Single cell analysis\n",
    "\n",
    "   * write simple script to read data, calculate correlation coefficients and plot their histogram\n",
    "   * use argparse to specify the input filename from the command line\n",
    "\n",
    "2) Building first workflow\n",
    "\n",
    "   * allow to write correlation coefficients to file\n",
    "   * seperate plotting and analysis\n",
    "\n",
    "2) Batch processing\n",
    "\n",
    "   * write data merge script\n",
    "   * write python script using subprocess, which run the correlation analysis on all its input files\n",
    "   * allow to plot histograms from more than one file\n",
    "\n",
    "3) Automating\n",
    "\n",
    "   * write dodo.py which runs the batch analysis on V1 data - define input files by hand\n",
    "   * add an extra input file to dependency list and show that the task will be automatically re-executed\n",
    "   * add plotting task based on v1 data only\n",
    "   * (optional) implement partially the batch run in the dodo file\n",
    "   * (optional) use task generators to avoid code duplicaton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
